{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install torch","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:35:29.554255Z","iopub.execute_input":"2023-05-18T18:35:29.554593Z","iopub.status.idle":"2023-05-18T18:35:42.294012Z","shell.execute_reply.started":"2023-05-18T18:35:29.554565Z","shell.execute_reply":"2023-05-18T18:35:42.292753Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.0.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch) (3.11.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install torchvision","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:36:03.919034Z","iopub.execute_input":"2023-05-18T18:36:03.920170Z","iopub.status.idle":"2023-05-18T18:36:15.447253Z","shell.execute_reply.started":"2023-05-18T18:36:03.920129Z","shell.execute_reply":"2023-05-18T18:36:15.446264Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.15.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision) (1.23.5)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from torchvision) (2.0.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (9.5.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2022.12.7)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (2.1.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision) (1.26.15)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (1.11.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (4.5.0)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.11.0)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->torchvision) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->torchvision) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->torchvision) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Load libraries\nimport os\nimport numpy as np\nimport torch\nimport glob\nimport torch.nn as nn\nfrom torchvision.transforms import transforms\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nfrom torch.autograd import Variable\nimport torchvision\nimport pathlib","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:36:15.449110Z","iopub.execute_input":"2023-05-18T18:36:15.450483Z","iopub.status.idle":"2023-05-18T18:36:19.306629Z","shell.execute_reply.started":"2023-05-18T18:36:15.450443Z","shell.execute_reply":"2023-05-18T18:36:19.305571Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"#checking for device\ndevice=torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:36:26.471893Z","iopub.execute_input":"2023-05-18T18:36:26.472535Z","iopub.status.idle":"2023-05-18T18:36:26.540686Z","shell.execute_reply.started":"2023-05-18T18:36:26.472502Z","shell.execute_reply":"2023-05-18T18:36:26.539549Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:36:36.138524Z","iopub.execute_input":"2023-05-18T18:36:36.139084Z","iopub.status.idle":"2023-05-18T18:36:36.147896Z","shell.execute_reply.started":"2023-05-18T18:36:36.139041Z","shell.execute_reply":"2023-05-18T18:36:36.146816Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"#Transforms\ntransformer=transforms.Compose([\n    transforms.Resize((150,150)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),  #0-255 to 0-1, numpy to tensors\n    transforms.Normalize([0.5,0.5,0.5], # 0-1 to [-1,1] , formula (x-mean)/std\n                        [0.5,0.5,0.5])\n])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:37:22.099674Z","iopub.execute_input":"2023-05-18T18:37:22.100099Z","iopub.status.idle":"2023-05-18T18:37:22.106829Z","shell.execute_reply.started":"2023-05-18T18:37:22.100068Z","shell.execute_reply":"2023-05-18T18:37:22.105850Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"\n#Path for training and testing directory\ntrain_path='/kaggle/input/vegetable-image-dataset/Vegetable Images/train'\ntest_path='/kaggle/input/vegetable-image-dataset/Vegetable Images/test'\n\ntrain_loader=DataLoader(\n    torchvision.datasets.ImageFolder(train_path,transform=transformer),\n    batch_size=64, shuffle=True\n)\ntest_loader=DataLoader(\n    torchvision.datasets.ImageFolder(test_path,transform=transformer),\n    batch_size=32, shuffle=True\n)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:39:24.966195Z","iopub.execute_input":"2023-05-18T18:39:24.967351Z","iopub.status.idle":"2023-05-18T18:39:31.752300Z","shell.execute_reply.started":"2023-05-18T18:39:24.967305Z","shell.execute_reply":"2023-05-18T18:39:31.751303Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#categories\nroot=pathlib.Path(train_path)\nclasses=sorted([j.name.split('/')[-1] for j in root.iterdir()])","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:40:04.465911Z","iopub.execute_input":"2023-05-18T18:40:04.467018Z","iopub.status.idle":"2023-05-18T18:40:04.473095Z","shell.execute_reply.started":"2023-05-18T18:40:04.466968Z","shell.execute_reply":"2023-05-18T18:40:04.471969Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"print(classes)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:40:20.825896Z","iopub.execute_input":"2023-05-18T18:40:20.826274Z","iopub.status.idle":"2023-05-18T18:40:20.833667Z","shell.execute_reply.started":"2023-05-18T18:40:20.826245Z","shell.execute_reply":"2023-05-18T18:40:20.831840Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"['Bean', 'Bitter_Gourd', 'Bottle_Gourd', 'Brinjal', 'Broccoli', 'Cabbage', 'Capsicum', 'Carrot', 'Cauliflower', 'Cucumber', 'Papaya', 'Potato', 'Pumpkin', 'Radish', 'Tomato']\n","output_type":"stream"}]},{"cell_type":"code","source":"#CNN Network\n\n\nclass ConvNet(nn.Module):\n    def __init__(self,num_classes=15):\n        super(ConvNet,self).__init__()\n        \n        #Output size after convolution filter\n        #((w-f+2P)/s) +1\n        \n        #Input shape= (256,3,150,150)\n        \n        self.conv1=nn.Conv2d(in_channels=3,out_channels=12,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,12,150,150)\n        self.bn1=nn.BatchNorm2d(num_features=12)\n        #Shape= (256,12,150,150)\n        self.relu1=nn.ReLU()\n        #Shape= (256,12,150,150)\n        \n        self.pool=nn.MaxPool2d(kernel_size=2)\n        #Reduce the image size be factor 2\n        #Shape= (256,12,75,75)\n        \n        \n        self.conv2=nn.Conv2d(in_channels=12,out_channels=20,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,20,75,75)\n        self.relu2=nn.ReLU()\n        #Shape= (256,20,75,75)\n        \n        \n        \n        self.conv3=nn.Conv2d(in_channels=20,out_channels=32,kernel_size=3,stride=1,padding=1)\n        #Shape= (256,32,75,75)\n        self.bn3=nn.BatchNorm2d(num_features=32)\n        #Shape= (256,32,75,75)\n        self.relu3=nn.ReLU()\n        #Shape= (256,32,75,75)\n        \n        \n        self.fc=nn.Linear(in_features=75 * 75 * 32,out_features=num_classes)\n        \n        \n        \n        #Feed forwad function\n        \n    def forward(self,input):\n        output=self.conv1(input)\n        output=self.bn1(output)\n        output=self.relu1(output)\n            \n        output=self.pool(output)\n            \n        output=self.conv2(output)\n        output=self.relu2(output)\n            \n        output=self.conv3(output)\n        output=self.bn3(output)\n        output=self.relu3(output)\n            \n            \n            #Above output will be in matrix form, with shape (256,32,75,75)\n            \n        output=output.view(-1,32*75*75)\n            \n            \n        output=self.fc(output)\n            \n        return output\n            ","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:43:04.772900Z","iopub.execute_input":"2023-05-18T18:43:04.773655Z","iopub.status.idle":"2023-05-18T18:43:04.786250Z","shell.execute_reply.started":"2023-05-18T18:43:04.773619Z","shell.execute_reply":"2023-05-18T18:43:04.784976Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"model=ConvNet(num_classes=15).to(device)\n","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:44:45.083579Z","iopub.execute_input":"2023-05-18T18:44:45.083969Z","iopub.status.idle":"2023-05-18T18:44:45.116139Z","shell.execute_reply.started":"2023-05-18T18:44:45.083933Z","shell.execute_reply":"2023-05-18T18:44:45.115254Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"#Optmizer and loss function\noptimizer=Adam(model.parameters(),lr=0.001,weight_decay=0.0001)\nloss_function=nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:45:07.625887Z","iopub.execute_input":"2023-05-18T18:45:07.626485Z","iopub.status.idle":"2023-05-18T18:45:07.631835Z","shell.execute_reply.started":"2023-05-18T18:45:07.626453Z","shell.execute_reply":"2023-05-18T18:45:07.630904Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"num_epochs=10","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:45:42.451757Z","iopub.execute_input":"2023-05-18T18:45:42.452148Z","iopub.status.idle":"2023-05-18T18:45:42.456585Z","shell.execute_reply.started":"2023-05-18T18:45:42.452117Z","shell.execute_reply":"2023-05-18T18:45:42.455582Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"#calculating the size of training and testing images\ntrain_count=len(glob.glob(train_path+'/**/*.jpg'))\ntest_count=len(glob.glob(test_path+'/**/*.jpg'))","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:46:03.780522Z","iopub.execute_input":"2023-05-18T18:46:03.780897Z","iopub.status.idle":"2023-05-18T18:46:03.877296Z","shell.execute_reply.started":"2023-05-18T18:46:03.780867Z","shell.execute_reply":"2023-05-18T18:46:03.876394Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"print(train_count,test_count)","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:46:31.808385Z","iopub.execute_input":"2023-05-18T18:46:31.808758Z","iopub.status.idle":"2023-05-18T18:46:31.816199Z","shell.execute_reply.started":"2023-05-18T18:46:31.808728Z","shell.execute_reply":"2023-05-18T18:46:31.815088Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"15000 3000\n","output_type":"stream"}]},{"cell_type":"code","source":"#Model training and saving best model\n\nbest_accuracy=0.0\n\nfor epoch in range(num_epochs):\n    \n    #Evaluation and training on training dataset\n    model.train()\n    train_accuracy=0.0\n    train_loss=0.0\n    \n    for i, (images,labels) in enumerate(train_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        optimizer.zero_grad()\n        \n        outputs=model(images)\n        loss=loss_function(outputs,labels)\n        loss.backward()\n        optimizer.step()\n        \n        \n        train_loss+= loss.cpu().data*images.size(0)\n        _,prediction=torch.max(outputs.data,1)\n        \n        train_accuracy+=int(torch.sum(prediction==labels.data))\n        \n    train_accuracy=train_accuracy/train_count\n    train_loss=train_loss/train_count\n    \n    \n    # Evaluation on testing dataset\n    model.eval()\n    \n    test_accuracy=0.0\n    for i, (images,labels) in enumerate(test_loader):\n        if torch.cuda.is_available():\n            images=Variable(images.cuda())\n            labels=Variable(labels.cuda())\n            \n        outputs=model(images)\n        _,prediction=torch.max(outputs.data,1)\n        test_accuracy+=int(torch.sum(prediction==labels.data))\n    \n    test_accuracy=test_accuracy/test_count\n    \n    \n    print('Epoch: '+str(epoch)+' Train Loss: '+str(train_loss)+' Train Accuracy: '+str(train_accuracy)+' Test Accuracy: '+str(test_accuracy))\n    \n    #Save the best model\n    if test_accuracy>best_accuracy:\n        torch.save(model.state_dict(),'best_checkpoint.model')\n        best_accuracy=test_accuracy","metadata":{"execution":{"iopub.status.busy":"2023-05-18T18:47:16.918094Z","iopub.execute_input":"2023-05-18T18:47:16.918486Z","iopub.status.idle":"2023-05-18T18:59:52.483877Z","shell.execute_reply.started":"2023-05-18T18:47:16.918456Z","shell.execute_reply":"2023-05-18T18:59:52.482751Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch: 0 Train Loss: tensor(7.1105) Train Accuracy: 0.6162 Test Accuracy: 0.688\nEpoch: 1 Train Loss: tensor(1.7956) Train Accuracy: 0.8226666666666667 Test Accuracy: 0.8383333333333334\nEpoch: 2 Train Loss: tensor(1.0291) Train Accuracy: 0.881 Test Accuracy: 0.856\nEpoch: 3 Train Loss: tensor(0.6583) Train Accuracy: 0.9104666666666666 Test Accuracy: 0.8626666666666667\nEpoch: 4 Train Loss: tensor(0.5283) Train Accuracy: 0.9276666666666666 Test Accuracy: 0.909\nEpoch: 5 Train Loss: tensor(0.3326) Train Accuracy: 0.9461333333333334 Test Accuracy: 0.8976666666666666\nEpoch: 6 Train Loss: tensor(0.2980) Train Accuracy: 0.9514 Test Accuracy: 0.9223333333333333\nEpoch: 7 Train Loss: tensor(0.2291) Train Accuracy: 0.9602666666666667 Test Accuracy: 0.9246666666666666\nEpoch: 8 Train Loss: tensor(0.1384) Train Accuracy: 0.9718 Test Accuracy: 0.918\nEpoch: 9 Train Loss: tensor(0.1432) Train Accuracy: 0.9723333333333334 Test Accuracy: 0.9036666666666666\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}